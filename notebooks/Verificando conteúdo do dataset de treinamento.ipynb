{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Verificando conteúdo do dataset de treinamento\n",
    "Vamos verificar se o conteúdo dos tweets capturados realmente corresponde ao sentimento\n",
    "rotulado e excluir os tweets que não tem nada a ver com o sentimento. Para isso, vamos\n",
    "verificar as palavras e temas mais frequentes, através das colocações, distribuição de\n",
    "frequência, trigramas e nuvem de palavras."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   Unnamed: 0                                              Texto Sentimento\n0           0  quero desejar a todos amigos um    , e creia 2...      feliz\n1           1  mais um ano ao lado dessas pessoas maravilhosa...      feliz\n2           2  final de tarde perfeito, estou renovada e pron...      feliz\n3           3  vamos adorar só aquele que é digno de todo o l...      feliz\n4           4     jesus! esse é meu sentimento neste dia. pas...      feliz",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Texto</th>\n      <th>Sentimento</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>quero desejar a todos amigos um    , e creia 2...</td>\n      <td>feliz</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>mais um ano ao lado dessas pessoas maravilhosa...</td>\n      <td>feliz</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>final de tarde perfeito, estou renovada e pron...</td>\n      <td>feliz</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>vamos adorar só aquele que é digno de todo o l...</td>\n      <td>feliz</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>jesus! esse é meu sentimento neste dia. pas...</td>\n      <td>feliz</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "path = '../datasets/'\n",
    "arquivo = path + 'tweets_ekman.csv'\n",
    "\n",
    "df_ekman = pd.read_csv(arquivo)\n",
    "df_ekman.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Verificando colocações\n",
    "Colocações são os bigramas que mais se repetem e podem nos dar alguma\n",
    "informação sobre o que ée mais relevante em um corpus. Neste caso, os\n",
    "tweets relacionados a cada uma das 5 emoções de Ekman."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def construir_corpus(serie_texto):\n",
    "    textos = list(serie_texto)\n",
    "    corpus = '. '.join(textos)\n",
    "    tokens = nltk.word_tokenize(corpus)\n",
    "    corpus = nltk.Text(tokens)\n",
    "\n",
    "    return corpus\n",
    "\n",
    "def escrever_colocacoes(corpus, nome_arquivo):\n",
    "    colocacoes = corpus.collocation_list()\n",
    "    path = 'arquivos/' + nome_arquivo\n",
    "    colocacoes_writer = open(path, 'w', encoding='utf-8')\n",
    "\n",
    "    for colocacao in colocacoes:\n",
    "        colocacoes_writer.write(colocacao + '\\n')\n",
    "\n",
    "    print('Arquivo criado com êxito!')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Colocações em trigramas\n",
    "Anteriormente, verificamos as colocações de duas palavras. Ou seja,\n",
    "bigramas. Vamos verificar agora quais os trigramas mais frequentes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Implementação da sumarização extrativa por tf-idf utilizando NLTK, de acordo com\n",
    "o tutorial disponível em: https://towardsdatascience.com/text-summarization-using-tf-idf-e64a0644ace3\n",
    "\"\"\"\n",
    "import math\n",
    "import nltk\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "\n",
    "def tokenizar(texto):\n",
    "    \"\"\"\n",
    "    Função para tokenizar as sentenças do texto passado como argumento.\n",
    "\n",
    "    :param texto: texto original\n",
    "    :return: o texto tokenizado\n",
    "    \"\"\"\n",
    "    periodos = sent_tokenize(texto)\n",
    "    total_de_documentos = len(periodos)\n",
    "\n",
    "    return total_de_documentos\n",
    "\n",
    "\n",
    "def matriz_frequencia(periodos):\n",
    "    \"\"\"\n",
    "    Cria uma matriz de frequência das palavras em cada sentença. Cada sentença é a chave e o valor é um\n",
    "    dicionário com a frequência de palavras.\n",
    "\n",
    "    :param periodos: A sentença que será analisada\n",
    "    :return: Uma matriz de frequência das palavras por sentença\n",
    "    \"\"\"\n",
    "    matriz_frequencia = {}\n",
    "    stopWords = set(stopwords.words('portuguese'))\n",
    "    ps = PorterStemmer()\n",
    "\n",
    "    for periodo in periodos:\n",
    "        tabela_freq = {}\n",
    "        palavras = word_tokenize(periodo)\n",
    "        for palavra in palavras:\n",
    "            palavra = palavra.lower()\n",
    "            palavra = ps.stem(palavra)\n",
    "            if palavra in stopWords:\n",
    "                continue\n",
    "            if palavra in tabela_freq:\n",
    "                tabela_freq[palavra] += 1\n",
    "            else:\n",
    "                tabela_freq[palavra] = 1\n",
    "\n",
    "        matriz_frequencia[periodo[:15]] = tabela_freq\n",
    "\n",
    "    return matriz_frequencia\n",
    "\n",
    "\n",
    "def criar_matriz_tf(matriz_frequencia):\n",
    "    \"\"\"\n",
    "    Calcula a frequência de termo de cada palavra e gera uma matriz.\n",
    "    Aqui cada parágrafo é considerado como um documento e o termo como uma palavra no parágrafo\n",
    "\n",
    "    :param matriz_frequencia: Matriz de frequência dos termos (palavras) por documento (parágrafo)\n",
    "    :return: Matriz TF (Term Frequency)\n",
    "    \"\"\"\n",
    "    matriz_tf = {}\n",
    "\n",
    "    for periodo, tabela_frequencia in matriz_frequencia.items():\n",
    "        tabela_tf = {}\n",
    "\n",
    "        quantidade_palavras_periodo = len(tabela_frequencia)\n",
    "        for palavra, cont in tabela_frequencia.items():\n",
    "            tabela_tf[palavra] = cont / quantidade_palavras_periodo\n",
    "\n",
    "        matriz_tf[periodo] = tabela_tf\n",
    "\n",
    "    return matriz_tf\n",
    "\n",
    "\n",
    "def criar_documentos_por_palavras(matriz_freq):\n",
    "    \"\"\"\n",
    "    Cria uma matriz que contém quantas sentenças possuem determinada palavra.\n",
    "\n",
    "    :param matriz_freq: Matriz de frequência das palavras por parágrafo\n",
    "    :return: Matriz de quantas sentenças possuem determinada palavra.\n",
    "    \"\"\"\n",
    "    tabela_palavra_por_doc = {}\n",
    "\n",
    "    for periodo, tabela_frequencia in matriz_freq.items():\n",
    "        for palavra, cont in tabela_frequencia.items():\n",
    "            if palavra in tabela_palavra_por_doc:\n",
    "                tabela_palavra_por_doc[palavra] += 1\n",
    "            else:\n",
    "                tabela_palavra_por_doc[palavra] = 1\n",
    "\n",
    "    return tabela_palavra_por_doc\n",
    "\n",
    "\n",
    "def criar_matriz_idf(matriz_frequencia, n_docs_por_palavras, total_docs):\n",
    "    \"\"\"\n",
    "    Calcula a matriz idf, considerando o parágrafo como o documento\n",
    "    e cada palavra no parágrafo como termo.\n",
    "\n",
    "    :param matriz_frequencia: Matriz de frequência das palavras por parágrafo\n",
    "    :param n_docs_por_palavras: Quantas sentenças possuem cada palavra\n",
    "    :param total_docs: Quantidade de documentos (parágrafos)\n",
    "    :return: Matriz IDF (Inverse Document Frequency)\n",
    "    \"\"\"\n",
    "    matriz_idf = {}\n",
    "\n",
    "    for periodo, tabela_frequencia in matriz_frequencia.items():\n",
    "        tabela_idf = {}\n",
    "        for palavra in tabela_frequencia.keys():\n",
    "            tabela_idf[palavra] = math.log10(total_docs / float(n_docs_por_palavras[palavra]))\n",
    "        matriz_idf[periodo] = tabela_idf\n",
    "\n",
    "    return matriz_idf\n",
    "\n",
    "\n",
    "def criar_matriz_tfidf(matriz_tf, matriz_idf):\n",
    "    \"\"\"\n",
    "    Multiplica os termos da matriz tf e da idf e cria uma nova matriz com o resultado\n",
    "\n",
    "    :param matriz_tf: Matriz TF (Term Frequency)\n",
    "    :param matriz_idf: Matriz IDF (Inverse Document Frequency)\n",
    "    :return: Matriz TF-IDF\n",
    "    \"\"\"\n",
    "    matriz_tfidf = {}\n",
    "\n",
    "    for (periodo1, tabela_freq1), (periodo2, tabela_freq2) in zip(matriz_tf.items(), matriz_idf.items()):\n",
    "        tabela_tfidf = {}\n",
    "        for (palavra1, valor1), (palavra2, valor2) in zip(tabela_freq1.items(),\n",
    "                                                          tabela_freq2.items()):\n",
    "            tabela_tfidf[palavra1] = float(valor1 * valor2)\n",
    "        matriz_tfidf[periodo1] = tabela_tfidf\n",
    "\n",
    "    return matriz_tfidf\n",
    "\n",
    "\n",
    "def pontuar_periodos(matriz_tfidf) -> dict:\n",
    "    \"\"\"\n",
    "    Dá um peso para cada parágrafo de acordo com sua pontuação na matriz TF-IDF\n",
    "\n",
    "    :param matriz_tfidf: Matriz TF-IDF\n",
    "    :return: Matriz com pesos para cada sentença\n",
    "    \"\"\"\n",
    "    valorPeriodo = {}\n",
    "\n",
    "    for periodo, tabela_freq in matriz_tfidf.items():\n",
    "        pontuacao_total_por_periodo = 0\n",
    "        cont_palavras_no_periodo = len(tabela_freq)\n",
    "        for palavra, pontuacao in tabela_freq.items():\n",
    "            pontuacao_total_por_periodo += pontuacao\n",
    "\n",
    "        valorPeriodo[periodo] = pontuacao_total_por_periodo / cont_palavras_no_periodo\n",
    "\n",
    "    return valorPeriodo\n",
    "\n",
    "\n",
    "def encontrar_pontuacao_media(valor_periodo):\n",
    "    \"\"\"\n",
    "    Calcula a pontuação média das pontuções dadas para cada sentença\n",
    "\n",
    "    :param valor_periodo: Pontuações dadas às sentenças\n",
    "    :return: Pontuação média entre as sentenças\n",
    "    \"\"\"\n",
    "    valores_soma = 0\n",
    "\n",
    "    for entrada in valor_periodo:\n",
    "        valores_soma += valor_periodo[entrada]\n",
    "\n",
    "    media = (valores_soma / len(valor_periodo))\n",
    "\n",
    "    return media\n",
    "\n",
    "\n",
    "def gerar_resumo(periodos, valor_periodo, pont_media):\n",
    "    \"\"\"\n",
    "    Gera um resumo com base na pontuação média das sentenças. Serão colocadas no resumo apenas as sentenças que\n",
    "    possuírem um valor superior ao produto da limiar escolhida pela pontuação média as sentenças.\n",
    "\n",
    "    :param periodos: texto original tokenizado\n",
    "    :param valor_periodo: Pontuação de uma sentença específica\n",
    "    :param pont_media: Pontuação média entre todas as sentenças\n",
    "    :return: Texto resumido\n",
    "    \"\"\"\n",
    "    contador_periodo = 0\n",
    "    resumo = ''\n",
    "\n",
    "    for periodo in periodos:\n",
    "        if periodo[:15] in valor_periodo and valor_periodo[periodo[:15]] >= pont_media:\n",
    "            resumo += \" \" + periodo\n",
    "            contador_periodo += 1\n",
    "\n",
    "    return resumo\n",
    "\n",
    "\n",
    "def tf_idf(texto):\n",
    "    \"\"\"\n",
    "    Faz o resumo de um texto utilizando o algoritmo TF-IDF\n",
    "\n",
    "    :param texto: O texto original a ser resumido\n",
    "    :return: O texto resumido\n",
    "    \"\"\"\n",
    "\n",
    "    # Tokenizamos as sentenças, ao invés das palavras\n",
    "    periodos = sent_tokenize(texto)\n",
    "\n",
    "    total_docs = len(periodos)\n",
    "\n",
    "    # Criamos uma matriz de frequência das palavras em cada sentença\n",
    "    # Cada sentença é a chave e o valor é um dicionário com a frequência de palavras\n",
    "    matriz_freq = matriz_frequencia(periodos)\n",
    "\n",
    "    # Calculamos a frequência de termo de cada palavra e geramos uma matriz\n",
    "    # Consideramos cada parágrafo como um documento e o termo como uma palavra no parágrafo\n",
    "    matriz_tf = criar_matriz_tf(matriz_freq)\n",
    "\n",
    "    # Uma matriz que contém quantas sentenças possuem determinada palavra\n",
    "    cont_doc_por_palavras = criar_documentos_por_palavras(matriz_freq)\n",
    "\n",
    "    # Aqui finalmente calculamos a matriz idf, lembrando que consideramos o parágrafo como o documento\n",
    "    # e cada palavra no parágrafo como termo\n",
    "    matriz_idf = criar_matriz_idf(matriz_freq, cont_doc_por_palavras, total_docs)\n",
    "\n",
    "    # Agora multiplicamos os termos da matriz tf e da idf e criamos uma nova matriz com o resultado\n",
    "    matriz_tfidf = criar_matriz_tfidf(matriz_tf, matriz_idf)\n",
    "\n",
    "    # Damos um peso para cada parágrafo de acordo com sua pontuação na matriz TF-IDF\n",
    "    pontuacao_periodos = pontuar_periodos(matriz_tfidf)\n",
    "\n",
    "    # Cada algoritmo de sumarização utiliza uma forma diferente para calcular a limiar\n",
    "    # Aqui, calculamos a pontuação média das pontuções dadas para cada sentença\n",
    "    pontuacao_media = encontrar_pontuacao_media(pontuacao_periodos)\n",
    "\n",
    "    # Por fim, são colocadas no resumo apenas as frases que pssuem uma pontuação maior que\n",
    "    # o valor rescolhido como limiar. Aqui, vamos escolher uma limiar de 1.1\n",
    "    limiar = 1.1\n",
    "    resumo = gerar_resumo(periodos, pontuacao_periodos, limiar * pontuacao_media)\n",
    "\n",
    "    return resumo\n",
    "\n",
    "def escrever_resumo(texto, nome_arquivo):\n",
    "    resumo = tf_idf(texto)\n",
    "    path = 'arquivos/' + nome_arquivo\n",
    "\n",
    "    with open(path, 'w', encoding='utf-8') as escritor:\n",
    "        escritor.writelines(resumo)\n",
    "\n",
    "    print('Resumo criado com êxito!')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo criado com êxito!\n",
      "Resumo criado com êxito!\n",
      "Arquivo criado com êxito!\n",
      "Resumo criado com êxito!\n",
      "Arquivo criado com êxito!\n",
      "Resumo criado com êxito!\n",
      "Arquivo criado com êxito!\n",
      "Resumo criado com êxito!\n",
      "Arquivo criado com êxito!\n",
      "Resumo criado com êxito!\n"
     ]
    }
   ],
   "source": [
    "# ['feliz', 'medo', 'triste', 'raiva', 'nojo']\n",
    "sentimentos = list(df_ekman['Sentimento'].unique())\n",
    "\n",
    "for sentimento in sentimentos:\n",
    "    txt = df_ekman.loc[df_ekman['Sentimento'] == sentimento, 'Texto']\n",
    "    corpus = construir_corpus(txt)\n",
    "\n",
    "    arquivo = sentimento + '_colocacoes.txt'\n",
    "    escrever_colocacoes(corpus=corpus, nome_arquivo=arquivo)\n",
    "    nome_resumo = sentimento + '_resumo.txt'\n",
    "    texto = ' '.join(corpus.tokens)\n",
    "    escrever_resumo(texto, nome_resumo)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}