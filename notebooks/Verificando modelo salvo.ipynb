{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pickle\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T08:36:06.103957400Z",
     "start_time": "2023-10-23T08:36:03.759783700Z"
    }
   },
   "id": "c629e4742ef24464"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-23T08:36:06.106953Z",
     "start_time": "2023-10-23T08:36:05.865032200Z"
    }
   },
   "outputs": [],
   "source": [
    "def carregar_modelo():\n",
    "    path = '../resources/modelos/modelo_classificacao_svc'\n",
    "    try:\n",
    "        modelo = pickle.load(open(path, 'rb'))\n",
    "        print('Modelo carregado com sucesso!\\n')\n",
    "\n",
    "        return modelo\n",
    "    except FileNotFoundError:\n",
    "        print('O arquivo não foi encontrado')\n",
    "    except IOError:\n",
    "        print('Erro ao carregar arquivo')\n",
    "        \n",
    "        \n",
    "def criar_embeddings(df_tweets):\n",
    "    try:\n",
    "        nlp = spacy.load('pt_core_news_lg')\n",
    "    except (IOError, OSError):\n",
    "        download('pt_core_news_lg')\n",
    "        nlp = spacy.load('pt_core_news_lg')\n",
    "    # desativamos todos os outros pipes que vem com o modelo nlp porque não preicsaremos deles\n",
    "    with nlp.disable_pipes():\n",
    "        # transformamos cada texto em um vetor e colocamos em uma array\n",
    "        print('Fazendo os word embeddings')\n",
    "        vetores = np.array([nlp(texto).vector for texto in df_tweets.Texto])\n",
    "\n",
    "    return vetores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fazendo os word embeddings\n",
      "Fazendo os word embeddings\n"
     ]
    }
   ],
   "source": [
    "path_datasets = '../resources/datasets'\n",
    "\n",
    "# importação dos dados\n",
    "df_treinamento = pd.read_csv(\n",
    "    f'{path_datasets}/tweets_ekman.csv',\n",
    "    usecols=['Texto', 'Sentimento']\n",
    ").dropna()\n",
    "df_alvo = pd.read_csv(f'{path_datasets}/tweets_pandemia.csv')\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    df_treinamento,\n",
    "    df_treinamento['Sentimento'],\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# processamento dos dados para word embeddings\n",
    "embeddings = criar_embeddings(x_train)\n",
    "embeddings_teste = criar_embeddings(x_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T08:42:19.941627300Z",
     "start_time": "2023-10-23T08:36:05.872449Z"
    }
   },
   "id": "60322a8b899ec975"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\home\\Desenvolvimento\\Analise-de-sentimentos-pandemia-covid19\\emocoes_venv\\Lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator LinearSVC from version 0.22.2.post1 when using version 1.3.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo carregado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "modelo_svc = carregar_modelo()\n",
    "previsoes = modelo_svc.predict(embeddings_teste)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T08:42:21.040025200Z",
     "start_time": "2023-10-23T08:42:19.956647300Z"
    }
   },
   "id": "ec4faaeb506bb593"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relatório Linear SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Neutro       0.73      0.95      0.83       495\n",
      "       feliz       0.63      0.62      0.62      1931\n",
      "        medo       0.53      0.39      0.45      2320\n",
      "        nojo       0.49      0.61      0.54      1648\n",
      "       raiva       0.17      0.40      0.24       562\n",
      "      triste       0.51      0.35      0.42      2097\n",
      "\n",
      "    accuracy                           0.50      9053\n",
      "   macro avg       0.51      0.55      0.52      9053\n",
      "weighted avg       0.53      0.50      0.50      9053\n"
     ]
    }
   ],
   "source": [
    "# testar performance\n",
    "print('Relatório Linear SVC')\n",
    "print(classification_report(y_test, previsoes))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T08:42:21.326839200Z",
     "start_time": "2023-10-23T08:42:21.064033Z"
    }
   },
   "id": "aab107caa445ec6b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
