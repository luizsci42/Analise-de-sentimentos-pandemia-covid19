{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Análise de Emoções em tweets relacionados à pandemia de Covid-19\n",
    "Este notebook é um experimento feito a partir do que foi desenvolvido durante minha iniciação científica (IC) durante os anos de 2020 e 2021. Os passos conduzidos durante a IC são descritos nas seções seguintes, de Entendimento do negócio à Preparação dos dados.\n",
    "\n",
    "O experimento conduido neste notebook irá se diferenciar do trabalho original a partir da seção de Modelagem, na qual será utilizada uma diferente abordagem a fim de explorar conceitos de tratamento de dados, treinamento e teste de performance de algoritmos de machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entendimento do negócio\n",
    "Com a crescente pervasividade da internet e das redes sociais, também cresce sua relevância para análise do debate público, sobretudo no que tange a saúde mental. O estudo de (Wolohan, 2009), por exemplo, faz uso de postagens do Reddit para mostrar o desenvolvimento ou agravamento de casos de depressão durante a pandemia de Covid-19, demonstrando a influência de uma saúde física no desenvolvimento de doenças mentais. \n",
    "\n",
    "Sendo assim, selecionamos o Twitter como fonte de dados textuais para compreensão do fenômenos da variação de emoções dos usuários do Twitter durante a pandemia de Covid-19, buscando assim ter um panorama de como a saúde mental dos brasileiros foi afetada pela pandemia.\n",
    "\n",
    "As emoções do tweets foram classificadas de acordo com as 5 emoções de Ekman (Ekman 2004), a saber: felicidade, tristeza, raiva, nojo e medo. Além dessas foi acrescida também a emoção \"neutro\", com a qual se espera classificar postagens de noticiários.\n",
    "\n",
    "## Entendimento dos dados\n",
    "O Twitter foi selecionado como fonte, tanto dos dados textuais de treinamento, quanto dos dados para análise final. A rede foi escolhida devido à facilidade de obtenção de dados, que pode ser feita através da API disponibilizada pela própria rede social, ou através de web crawlers disponíveis para a plataforma.\n",
    "\n",
    "### Conjunto de emoções de Ekman\n",
    "Devido à escassez de conjuntos de dados (_datasets_) com textos rotulados com as emoçoes de Ekman, foi necessário fazer a coleta desses dados. Dessa forma, o conjunto de treinamento foi criado coletando _tweets_ que contivessem hashtags\n",
    "relacionadas às emoções de Ekman, como proposto por (Go et al. 2009), (Nodarakis et al. 2016) e (Kouloumpis et al. 2011), que mostram como, na maioria das vezes, as hashtags utilizadas refletem o sentimento predominante na respectiva postagem.\n",
    "\n",
    "### Conjunto de tweets referentes à pandemia de Covid-19\n",
    "Para o conjunto de dados referente à pandemia de Covid-19, o qual se pretende analisar, foram selecionados tweets que contivessem os termos \"isolamento\", \"quarentena\", \"covid\", \"corona\", \"coronavirus\", \"corona virus\", \"covid-19\", \"covid19\" e/ou \"covid 19\".\n",
    "\n",
    "## Preparação dos dados\n",
    "Nesta fase, é removido o \"ruído\" do texto. Assim, foram retirados dos textos de ambos os _datasets_, os emojis, URLS, citações a outros perfis, hashtags e stopwords.\n",
    "\n",
    "Para o conjunto de treinamento, foram ainda removidas as palavras que coincidiam com o rótulo, para evitar que o modelo criasse overfitting devido à citação da própria classificação dentro do texto. Por exemplo, um tweet cujo conteúdo fosse \"estou muito feliz hoje\" seria obviamente classificado como feliz, enviesando o modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelagem\n",
    "Durante a execução do PIBIC, o conjunto de treinamento foi balanceado para que o modelo não desse mais peso a uma classe que às demais. Neste notebook, o experimento consiste em conseguir treinar um modelo de performance igual ou superior ao modelo desenvolvido durante a IC, mas sem balancear o conjunto de treinamento.\n",
    "\n",
    "O primeiro passo é a importação das bibliotecas necessárias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-23T23:50:50.181881800Z",
     "start_time": "2023-10-23T23:50:11.161217Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "from spacy.cli.download import download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como os modelos de _machine learning_ aceitam apenas entradas numéricas, é necessário o uso de alguma técnica que codifique o texto em algum tipo de representação numérica. Para isso o uso de _sentence embeddings_ desempenha um papel essencial. Em termos gerais, as frases são convertidas em representações vetoriais.\n",
    "\n",
    "Para realizar essa codificação, foi feito uso do modelo \"pt_core_news_lg\" da biblioteca SpaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-23T23:50:50.183883400Z",
     "start_time": "2023-10-23T23:50:50.135882700Z"
    }
   },
   "outputs": [],
   "source": [
    "def criar_embeddings(df_tweets):\n",
    "    try:\n",
    "        nlp = spacy.load('pt_core_news_lg')\n",
    "    except (IOError, OSError):\n",
    "        download('pt_core_news_lg')\n",
    "        nlp = spacy.load('pt_core_news_lg')\n",
    "    # desativamos todos os outros pipes que vem com o modelo nlp porque não preicsaremos deles\n",
    "    with nlp.disable_pipes():\n",
    "        # transformamos cada tweet em um vetor e colocamos em uma array\n",
    "        print('Fazendo os word embeddings')\n",
    "        vetores = np.array([nlp(texto).vector for texto in df_tweets.Texto])\n",
    "\n",
    "    return vetores\n",
    "\n",
    "\n",
    "def ler_modelo(path: str):\n",
    "    return pickle.load(open(path, 'rb'))\n",
    "\n",
    "\n",
    "def salvar_modelo(path: str, modelo):\n",
    "    return pickle.dump(modelo, open(path, 'wb'))    \n",
    "\n",
    "\n",
    "def fazer_amostragem(train_dataset: pd.DataFrame):\n",
    "    \"\"\"\n",
    "\n",
    "    :param train_dataset:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    sentimentos = train_dataset['Sentimento'].unique()\n",
    "    df = pd.DataFrame([])\n",
    "\n",
    "    for sentimento in sentimentos:\n",
    "        df_filtrado = train_dataset.loc[train_dataset['Sentimento'] == sentimento][:600]\n",
    "        df = pd.concat([df, df_filtrado])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O conjunto de dados textuais rotulados com as emoções de Ekman é carregado e dividido em subconjuntos de treinamento e de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-23T23:50:51.222256800Z",
     "start_time": "2023-10-23T23:50:50.136884200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_datasets = '../resources/datasets'\n",
    "\n",
    "# importação dos dados\n",
    "df_treinamento = pd.read_csv(\n",
    "    f'{path_datasets}/tweets_ekman.csv',\n",
    "    usecols=['Texto', 'Sentimento']\n",
    ").dropna()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    df_treinamento,\n",
    "    df_treinamento['Sentimento'],\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os embeddings são treinados e salvos, ou lidos, caso já exista um arquivo salvo com os embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-23T23:50:51.951523100Z",
     "start_time": "2023-10-23T23:50:51.229255100Z"
    }
   },
   "outputs": [],
   "source": [
    "# processamento dos dados para word embeddings\n",
    "path_embeddings_treinamento = '../resources/modelos/embeddings_treinamento.pkl'\n",
    "path_embeddings_teste = '../resources/modelos/embeddings_teste.pkl'\n",
    "\n",
    "if os.path.exists(path_embeddings_treinamento):\n",
    "    embeddings = ler_modelo(path_embeddings_treinamento)\n",
    "else:\n",
    "    embeddings = criar_embeddings(x_train)\n",
    "    salvar_modelo(path_embeddings_treinamento, embeddings)\n",
    "\n",
    "if os.path.exists(path_embeddings_teste):\n",
    "    embeddings_teste = ler_modelo(path_embeddings_teste)\n",
    "else:\n",
    "    embeddings_teste = criar_embeddings(x_test)\n",
    "    salvar_modelo(path_embeddings_teste, embeddings_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os modelos são treinados e salvos, ou lidos, caso já exista um arquivo salvo.\n",
    "\n",
    "São treinados 3 algoritmos de _machine learning_: LinearSVC, Logistic Regression e Random Forest. Os três são bem utilizados na literatura para a tarefa de classificação de emoções.\n",
    "\n",
    "Os embeddings criados anteriormente serão utilizados como entrada de cada um dos algoritmos. Ao fim serão comparados seus respectivos desempenhos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-23T23:50:56.128221800Z",
     "start_time": "2023-10-23T23:50:51.958521400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_svc = '../resources/modelos/svc.pkl'\n",
    "path_lgr = '../resources/modelos/logistic_regression.pkl'\n",
    "path_forest = '../resources/modelos/forest.pkl'\n",
    "\n",
    "if os.path.exists(path_svc):\n",
    "    svc = ler_modelo(path_svc)\n",
    "else:\n",
    "    svc = LinearSVC(C=100, random_state=0, dual=True, max_iter=10000)\n",
    "    svc.fit(embeddings, y_train)\n",
    "    salvar_modelo(path_svc, svc)\n",
    "    \n",
    "if os.path.exists(path_lgr):\n",
    "    lgr = ler_modelo(path_lgr)\n",
    "else:\n",
    "    lgr = LogisticRegression(random_state=0)\n",
    "    lgr.fit(embeddings, y_train)\n",
    "    salvar_modelo(path_lgr, lgr)\n",
    "\n",
    "if os.path.exists(path_forest):\n",
    "    forest = ler_modelo(path_forest)\n",
    "else:\n",
    "    forest = RandomForestClassifier(random_state=0, n_jobs=-1)\n",
    "    forest.fit(embeddings, y_train)\n",
    "    salvar_modelo(path_forest, forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-23T23:50:57.410717900Z",
     "start_time": "2023-10-23T23:50:56.129220100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# previsões\n",
    "previsoes_svc = svc.predict(embeddings_teste)\n",
    "previsoes_lgr = lgr.predict(embeddings_teste)\n",
    "previsoes_forest = forest.predict(embeddings_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-23T23:50:58.131769400Z",
     "start_time": "2023-10-23T23:50:57.408712500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relatório Linear SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Neutro       0.96      0.94      0.95       495\n",
      "       feliz       0.74      0.45      0.56      1931\n",
      "        medo       0.35      0.83      0.50      2320\n",
      "        nojo       0.50      0.24      0.32      1648\n",
      "       raiva       0.13      0.18      0.16       562\n",
      "      triste       0.45      0.08      0.14      2097\n",
      "\n",
      "    accuracy                           0.43      9053\n",
      "   macro avg       0.52      0.45      0.44      9053\n",
      "weighted avg       0.50      0.43      0.40      9053\n"
     ]
    }
   ],
   "source": [
    "# testar performance\n",
    "print('Relatório Linear SVC')\n",
    "print(classification_report(y_test, previsoes_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-23T23:50:58.454000400Z",
     "start_time": "2023-10-23T23:50:58.094768200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relatório Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Neutro       0.97      0.94      0.96       495\n",
      "       feliz       0.71      0.73      0.72      1931\n",
      "        medo       0.54      0.61      0.57      2320\n",
      "        nojo       0.61      0.63      0.62      1648\n",
      "       raiva       0.45      0.12      0.19       562\n",
      "      triste       0.52      0.53      0.53      2097\n",
      "\n",
      "    accuracy                           0.61      9053\n",
      "   macro avg       0.63      0.59      0.60      9053\n",
      "weighted avg       0.60      0.61      0.60      9053\n"
     ]
    }
   ],
   "source": [
    "print('Relatório Logistic Regression')\n",
    "print(classification_report(y_test, previsoes_lgr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-23T23:50:58.697388800Z",
     "start_time": "2023-10-23T23:50:58.377002300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relatório Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Neutro       0.95      0.87      0.91       495\n",
      "       feliz       0.63      0.66      0.64      1931\n",
      "        medo       0.45      0.56      0.50      2320\n",
      "        nojo       0.48      0.43      0.46      1648\n",
      "       raiva       0.96      0.05      0.09       562\n",
      "      triste       0.45      0.47      0.46      2097\n",
      "\n",
      "    accuracy                           0.52      9053\n",
      "   macro avg       0.66      0.51      0.51      9053\n",
      "weighted avg       0.55      0.52      0.51      9053\n"
     ]
    }
   ],
   "source": [
    "print('Relatório Random Forest')\n",
    "print(classification_report(y_test, previsoes_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T00:10:35.746097600Z",
     "start_time": "2023-10-23T23:50:58.644393800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pontuacoes_logreg = cross_val_score(lgr, embeddings_teste, y_test, cv=5, n_jobs=-1, scoring='f1_weighted')\n",
    "pontuacoes_svc = cross_val_score(svc, embeddings_teste, y_test, cv=5, n_jobs=-1, scoring='f1_weighted')\n",
    "pontuacoes_forest = cross_val_score(forest, embeddings_teste, y_test, cv=5, n_jobs=-1, scoring='f1_weighted');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T00:10:35.843967100Z",
     "start_time": "2023-10-24T00:10:35.752095600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lista de pontuações: [0.56582297 0.58788242 0.574865   0.5794129  0.56741404]\n",
      "Média: 0.5750794670048374\n",
      "Lista de pontuações: [0.44221795 0.51446641 0.35366093 0.47581766 0.47062506]\n",
      "Média: 0.45135760052701085\n",
      "Lista de pontuações: [0.47940858 0.49138109 0.46536405 0.46713247 0.48691761]\n",
      "Média: 0.4780407583044698\n"
     ]
    }
   ],
   "source": [
    "def exibir_pontuacoes(pontuacoes):\n",
    "    soma_ponuacoes = 0\n",
    "\n",
    "    for valor in pontuacoes:\n",
    "        soma_ponuacoes += valor\n",
    "        \n",
    "    media = soma_ponuacoes / len(pontuacoes)\n",
    "    \n",
    "    print(f'Lista de pontuações: {pontuacoes}\\nMédia: {media}' )\n",
    "    \n",
    "exibir_pontuacoes(pontuacoes_logreg)\n",
    "exibir_pontuacoes(pontuacoes_svc)\n",
    "exibir_pontuacoes(pontuacoes_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "O modelo Logistic Regression obteve o melhor desempenho dentre os modelos, enquanto que o LinearSVC e o Random Forest tiveram desempenhos semelhantes. No entanto, nenhum deles se mostrou satisfatório, atingindo menos de 60% de f1-score. De acordo com os relatórios, os três modelos tiveram baixo desempenho na classe \"raiva\". Outras medidas devem ser tomadas para tentar melhorar o desempenho.\n",
    "\n",
    "## Trabalhos Futuros\n",
    "Realizar o ajuste de hiperparâmetros para tentar obter um modelo de logistic regression com um desempenho ainda superior."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tweets_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
