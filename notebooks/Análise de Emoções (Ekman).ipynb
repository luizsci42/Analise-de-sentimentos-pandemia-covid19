{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Análise de Emoções em tweets relacionados à pandemia de Covid-19\n",
    "\n",
    "## Introdução\n",
    "\n",
    "* Motivação\n",
    "* "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-23T23:50:50.181881800Z",
     "start_time": "2023-10-23T23:50:11.161217Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "from spacy.cli.download import download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-23T23:50:50.183883400Z",
     "start_time": "2023-10-23T23:50:50.135882700Z"
    }
   },
   "outputs": [],
   "source": [
    "def criar_embeddings(df_tweets):\n",
    "    try:\n",
    "        nlp = spacy.load('pt_core_news_lg')\n",
    "    except (IOError, OSError):\n",
    "        download('pt_core_news_lg')\n",
    "        nlp = spacy.load('pt_core_news_lg')\n",
    "    # desativamos todos os outros pipes que vem com o modelo nlp porque não preicsaremos deles\n",
    "    with nlp.disable_pipes():\n",
    "        # transformamos cada texto em um vetor e colocamos em uma array\n",
    "        print('Fazendo os word embeddings')\n",
    "        vetores = np.array([nlp(texto).vector for texto in df_tweets.Texto])\n",
    "\n",
    "    return vetores\n",
    "\n",
    "\n",
    "def ler_modelo(path: str):\n",
    "    return pickle.load(open(path, 'rb'))\n",
    "\n",
    "\n",
    "def salvar_modelo(path: str, modelo):\n",
    "    return pickle.dump(modelo, open(path, 'wb'))    \n",
    "\n",
    "\n",
    "def fazer_amostragem(train_dataset: pd.DataFrame):\n",
    "    \"\"\"\n",
    "\n",
    "    :param train_dataset:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    sentimentos = train_dataset['Sentimento'].unique()\n",
    "    df = pd.DataFrame([])\n",
    "\n",
    "    for sentimento in sentimentos:\n",
    "        df_filtrado = train_dataset.loc[train_dataset['Sentimento'] == sentimento][:600]\n",
    "        df = pd.concat([df, df_filtrado])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "path_datasets = '../resources/datasets'\n",
    "\n",
    "# importação dos dados\n",
    "df_treinamento = pd.read_csv(\n",
    "    f'{path_datasets}/tweets_ekman.csv',\n",
    "    usecols=['Texto', 'Sentimento']\n",
    ").dropna()\n",
    "df_alvo = pd.read_csv(f'{path_datasets}/tweets_pandemia.csv')\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    df_treinamento,\n",
    "    df_treinamento['Sentimento'],\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T23:50:51.222256800Z",
     "start_time": "2023-10-23T23:50:50.136884200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-23T23:50:51.951523100Z",
     "start_time": "2023-10-23T23:50:51.229255100Z"
    }
   },
   "outputs": [],
   "source": [
    "# processamento dos dados para word embeddings\n",
    "path_embeddings_treinamento = '../resources/modelos/embeddings_treinamento.pkl'\n",
    "path_embeddings_teste = '../resources/modelos/embeddings_teste.pkl'\n",
    "\n",
    "if os.path.exists(path_embeddings_treinamento):\n",
    "    embeddings = ler_modelo(path_embeddings_treinamento)\n",
    "else:\n",
    "    embeddings = criar_embeddings(x_train)\n",
    "    salvar_modelo(path_embeddings_treinamento, embeddings)\n",
    "\n",
    "if os.path.exists(path_embeddings_teste):\n",
    "    embeddings_teste = ler_modelo(path_embeddings_teste)\n",
    "else:\n",
    "    embeddings_teste = criar_embeddings(x_test)\n",
    "    salvar_modelo(path_embeddings_teste, embeddings_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "path_svc = '../resources/modelos/svc.pkl'\n",
    "path_lgr = '../resources/modelos/logistic_regression.pkl'\n",
    "path_forest = '../resources/modelos/forest.pkl'\n",
    "\n",
    "if os.path.exists(path_svc):\n",
    "    svc = ler_modelo(path_svc)\n",
    "else:\n",
    "    svc = LinearSVC(C=100, random_state=0, dual=True, max_iter=10000)\n",
    "    svc.fit(embeddings, y_train)\n",
    "    salvar_modelo(path_svc, svc)\n",
    "    \n",
    "if os.path.exists(path_lgr):\n",
    "    lgr = ler_modelo(path_lgr)\n",
    "else:\n",
    "    lgr = LogisticRegression(random_state=0)\n",
    "    lgr.fit(embeddings, y_train)\n",
    "    salvar_modelo(path_lgr, lgr)\n",
    "\n",
    "if os.path.exists(path_forest):\n",
    "    forest = ler_modelo(path_forest)\n",
    "else:\n",
    "    forest = RandomForestClassifier(random_state=0, n_jobs=-1)\n",
    "    forest.fit(embeddings, y_train)\n",
    "    salvar_modelo(path_forest, forest)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T23:50:56.128221800Z",
     "start_time": "2023-10-23T23:50:51.958521400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# previsões\n",
    "previsoes_svc = svc.predict(embeddings_teste)\n",
    "previsoes_lgr = lgr.predict(embeddings_teste)\n",
    "previsoes_forest = forest.predict(embeddings_teste)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T23:50:57.410717900Z",
     "start_time": "2023-10-23T23:50:56.129220100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-23T23:50:58.131769400Z",
     "start_time": "2023-10-23T23:50:57.408712500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relatório Linear SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Neutro       0.96      0.94      0.95       495\n",
      "       feliz       0.74      0.45      0.56      1931\n",
      "        medo       0.35      0.83      0.50      2320\n",
      "        nojo       0.50      0.24      0.32      1648\n",
      "       raiva       0.13      0.18      0.16       562\n",
      "      triste       0.45      0.08      0.14      2097\n",
      "\n",
      "    accuracy                           0.43      9053\n",
      "   macro avg       0.52      0.45      0.44      9053\n",
      "weighted avg       0.50      0.43      0.40      9053\n"
     ]
    }
   ],
   "source": [
    "# testar performance\n",
    "print('Relatório Linear SVC')\n",
    "print(classification_report(y_test, previsoes_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-23T23:50:58.454000400Z",
     "start_time": "2023-10-23T23:50:58.094768200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relatório Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Neutro       0.97      0.94      0.96       495\n",
      "       feliz       0.71      0.73      0.72      1931\n",
      "        medo       0.54      0.61      0.57      2320\n",
      "        nojo       0.61      0.63      0.62      1648\n",
      "       raiva       0.45      0.12      0.19       562\n",
      "      triste       0.52      0.53      0.53      2097\n",
      "\n",
      "    accuracy                           0.61      9053\n",
      "   macro avg       0.63      0.59      0.60      9053\n",
      "weighted avg       0.60      0.61      0.60      9053\n"
     ]
    }
   ],
   "source": [
    "print('Relatório Logistic Regression')\n",
    "print(classification_report(y_test, previsoes_lgr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-23T23:50:58.697388800Z",
     "start_time": "2023-10-23T23:50:58.377002300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relatório Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Neutro       0.95      0.87      0.91       495\n",
      "       feliz       0.63      0.66      0.64      1931\n",
      "        medo       0.45      0.56      0.50      2320\n",
      "        nojo       0.48      0.43      0.46      1648\n",
      "       raiva       0.96      0.05      0.09       562\n",
      "      triste       0.45      0.47      0.46      2097\n",
      "\n",
      "    accuracy                           0.52      9053\n",
      "   macro avg       0.66      0.51      0.51      9053\n",
      "weighted avg       0.55      0.52      0.51      9053\n"
     ]
    }
   ],
   "source": [
    "print('Relatório Random Forest')\n",
    "print(classification_report(y_test, previsoes_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "pontuacoes_logreg = cross_val_score(lgr, embeddings_teste, y_test, cv=5, n_jobs=-1, scoring='f1_weighted')\n",
    "pontuacoes_svc = cross_val_score(svc, embeddings_teste, y_test, cv=5, n_jobs=-1, scoring='f1_weighted')\n",
    "pontuacoes_forest = cross_val_score(forest, embeddings_teste, y_test, cv=5, n_jobs=-1, scoring='f1_weighted');"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T00:10:35.746097600Z",
     "start_time": "2023-10-23T23:50:58.644393800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lista de pontuações: [0.56582297 0.58788242 0.574865   0.5794129  0.56741404]\n",
      "Média: 0.5750794670048374\n",
      "Lista de pontuações: [0.44221795 0.51446641 0.35366093 0.47581766 0.47062506]\n",
      "Média: 0.45135760052701085\n",
      "Lista de pontuações: [0.47940858 0.49138109 0.46536405 0.46713247 0.48691761]\n",
      "Média: 0.4780407583044698\n"
     ]
    }
   ],
   "source": [
    "def exibir_pontuacoes(pontuacoes):\n",
    "    soma_ponuacoes = 0\n",
    "\n",
    "    for valor in pontuacoes:\n",
    "        soma_ponuacoes += valor\n",
    "        \n",
    "    media = soma_ponuacoes / len(pontuacoes)\n",
    "    \n",
    "    print(f'Lista de pontuações: {pontuacoes}\\nMédia: {media}' )\n",
    "    \n",
    "exibir_pontuacoes(pontuacoes_logreg)\n",
    "exibir_pontuacoes(pontuacoes_svc)\n",
    "exibir_pontuacoes(pontuacoes_forest)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T00:10:35.843967100Z",
     "start_time": "2023-10-24T00:10:35.752095600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "O modelo Logistic Regression obteve o melhor desempenho dentre os modelos, enquanto que o LinearSVC e o Random Forest tiveram desempenhos semelhantes.\n",
    "\n",
    "## Trabalhos Futuros\n",
    "Realizar o ajuste de hiperparâmetros para tentar obter um modelo de logistic regression com um desempenho ainda superior."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tweets_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
